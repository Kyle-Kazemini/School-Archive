---
title: "MATH 3080 Lab Project 8"
author: "Kyle Kazemini"
date: "01/23/2020"
output:
  pdf_document:
    toc: TRUE
---

# Problem 1 (Verzani problem 11.1)

*For the `Cars93` (**MASS**) data set, answer the following:*

1. *For `MPG.highway` modeled by `Horsepower`, find the simple regression
   coefficients. What is the predicted mileage for a car with 225 horsepower?*

```{r, error = TRUE}
library(MASS)
data("Cars93")

fit <- lm(MPG.highway ~ Horsepower, data = Cars93)
fit
#This shows both coefficients for the simple regression

predict(fit, Horesepower = 225)
#The predict function shows predicted values for a Horsepower of 225
```

2. *Fit the linear model with `MPG.highway` modeled by `Weight`. Find the
   predicted highway mileage of a 6,400 pound HUMMER H2 and a 2,524 pound MINI
   Cooper.*

```{r, error = TRUE}
fit <- lm(MPG.highway ~ Weight, data = Cars93)
fit
#Create a regression model

pre1 <- predict(fit, Weight = 6400)
pre1
#Predict highway MPG values for the 6,400 lb Hummer H2

pre2 <- predict(fit, Weight = 2524)
pre2
#Predict highway MPG values for the 2,524 lb Mini Cooper
```

3. *Fit the linear model `Max.Price` modeled by `Min.Price`. Why might you
   expect the slope to be around 1?*

```{r, error = TRUE}
fit <- lm(Max.Price ~ Min.Price, data = Cars93)
fit
#The slope in this simple regression model is expected to be around 1 because as min price increases, so does max price
#The price of a car is expected to float around a small range of values
```

**BONUS**: *Can you think of any other linear relationships among the
variables?*

```{r, error = TRUE}
```

# Problem 2 (Verzani problem 11.2)

*For the data set `MLBattend` (**UsingR**) concerning Major League Baseball
attendance, fit a linear model of `attendance` modeled by `wins`. What is the
predicted increase in attendance if a team that won 80 games last year wins 90
this year?*

```{r, error = TRUE}
library(UsingR)
data("MLBattend")

fit <- lm(attendance ~ wins, data = MLBattend)
fit
#Create a simple linear regression model

pre1 <- predict(fit, wins = 80, year = 2019)
pre1
#Make a prediction for 80 wins in 2019

pre2 <- predict(fit, wins = 90, year = 2020)
pre2
#Make a prediction for 90 wins this year

#Based on these prediction values, a change of 10 wins seems to have little to no effect on attendance
```

# Problem 3 (Verzani problem 11.3)

*People often predict children's future height by using their 2-year-old height.
A common rule is to double the height. The table contains data for eight
people's heights as 2-year-olds and as adults. Using the data, what is the
predicted adult height for a 2-year-old who is 33 inches tall?*

Group       |    |    |    |    |    |    |    |    |
------------|----|----|----|----|----|----|----|----|
Age 2 (in.) | 39 | 30 | 32 | 34 | 35 | 36 | 36 | 30 |
Adult (in.) | 71 | 63 | 63 | 67 | 68 | 68 | 70 | 64 |

```{r, error = TRUE}
age2 <- c(39, 30, 32, 34, 35, 36, 36, 30)
ageAdult <- c(71, 63, 63, 67, 68, 68, 70, 64)

fit <- lm(ageAdult ~ age2)
#Create a regression

pred <- predict(fit, age2 = 33)
pred
#Predict and show adult height for a 2-year old height of 33 inches
```

# Problem 4 (Verzani problem 11.4)

*The `galton` (**UsingR**) data set contains data collected by Francis Galton in
1885 concerning the influence a parent's height has on a child's height. Fit a
linear model for a child's height modeled by his parent's height. Make a
scatterplot with a regression line. (Is this data set a good candidate for using
`jitter()`?) What is the value of $\hat{\beta}_1$, and why is this of interest?*

```{r, error = TRUE}
data("galton")

fit <- lm(child ~ parent, data = galton)
fit
#Create the regression model

plot(child ~ parent, data = galton)
#Generate a scatterplot for the data

abline(fit)
#Create a regression line for the plot

#The data is not a good candidate for using jitter() because there are no ties in the 
#data and there is no reason for noise to be added

#From the regression, the value of $\hat{\beta}_1$ is 0.6463
#This is of interest because it tells us how the relationship between parent and child height changes as parent height increases
```

# Problem 5 (Verzani problem 11.5)

*The formulas*

$$\hat{\beta}_1 = \frac{\sum_{i = 1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i =
1}^n (x_i - \bar{x})^2},$$

$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x},$$

*and the prediction line equation can be rewritten in terms of the correlation
coefficient, $r$, as*

$$\frac{\hat{y}_i - \bar{y}}{s_y} = r \frac{x_i - \bar{x}}{s_x}.$$

*Thus the five summary numbers: the two means, the standard deviations, and the
correlation coefficient are fundamental for regression analysis.*

*This is interpreted as follows. Scaled differences of $\hat{y}_i$ from the mean
$\bar{y}$ are less than the scaled differences of $x_i$ from $\bar{x}$, as
$\left|r\right| \le 1$. That is, "regression" toward the mean, as unusually
large differences from the mean are lessened in their prediction for $y$.*

*For the data set `galton` (**UsingR**) use `scale()` on the variables `parent`
and `child`, and then model the height of the child by the height of the parent.
What are the estimates for $r$ and $\beta_1$.*

```{r, error = TRUE}
sParent <- scale(galton$parent)
sChild <- scale(galton$child)
#Scale both the parent and child variables

fit <- lm(sChild ~ sParent)
#Create the regression

summary(fit)
#Use summary to show R-squared

r <- sqrt(0.2015)
r
#Take the square root to get r

sx <- sd(sParent)
sx

sy <- sd(sChild)
sy
#Calculate both standard deviations in order to find Beta1

beta1 <- r * (sy / sx)
beta1
#Calculate Beta1
```

